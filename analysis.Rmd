---
title: "Data Analysis Script of the Pointing Experiment Project 2"
output: html_document
---

```{r setup, message=FALSE, echo=FALSE}

## Clear workspace
rm(list=ls())

# =============================================
# Load Packages
pacman::p_load(
  # data processing
  plyr,
  tidyverse,  # collection of the tidyverse packages
  stringr,    #   - for string functions
  forcats,    #   - utility functions for working with factor levels
  lubridate,  #   - utility for parsing and performing arithematic on dates 
  tools,      #   - for package development, administration and documentation
  data.table, #   - for data manipulation 
  tibble     #   - to create data frames
)
```

## Data Import
Load all Data that is stored in the corresponding folder
```{r import}
# Create a function that imports all .csv files from a directory "ExperimentalData"
# TODO: Put the gathered data in the "ExperimentalData" Folder & use the second line below
file_list <- list.files(path = file.path("PilotData"), pattern = "*.csv", recursive = TRUE, full.names = TRUE)
# file_list <- list.files(path = file.path("ExperimentalData"), pattern = "*.csv", recursive = TRUE, full.names = TRUE)

data_raw <- do.call("rbind", lapply(file_list, function(filename)
  data.frame(read.delim(filename, sep = ";"))))

# Keep only the columns of interest and give them more readable names
data <- data_raw %>% 
  select(
    Participant = Part,
    Condition = Cond,
    Block,
    TrialNumber = Trial,
    TargetNumber = Click,
    TargetHighlighted = Click_t,
    TargetClicked = Tar_t,
    PosX,
    PosY,
    Distance = Dist,
    TargetIsHit = Succ
  )

```

## Data Clean Up
Before we start with the analysis, we will reduce the dataset to the necessary attributes and calcutate the aggregated values.
```{r clean up}
# Keep only the columns of interest and give them more readable names
data <- data_raw %>% 
  select(
    Participant = Part,
    Condition = Cond,
    Block,
    TrialNumber = Trial,
    TargetNumber = Click,
    TargetHighlighted = Click_t,
    TargetClicked = Tar_t,
    PosX,
    PosY,
    Distance = Dist,
    TargetIsHit = Succ
  )


# Renaming of cell values in a more meaningful way
data$Condition[data$Condition == '0'] <- "Regular Edge"
data$Condition[data$Condition == '1'] <- "Virtual Edge"
# TODO if the Demo-Block is still included in the data
data$Block[data$Block == '0'] <- "Demo"
data$TargetIsHit[data$TargetIsHit == '0'] <- FALSE
data$TargetIsHit[data$TargetIsHit == '1'] <- TRUE
# TODO Controll if dataformat still matches the one from the files imported
data$TargetHighlighted <- as.POSIXct(data$TargetHighlighted, format = "%d-%m-%Y %H:%M:%S:%OS")
data$TargetClicked <- as.POSIXct(data$TargetClicked, format = "%d-%m-%Y %H:%M:%S:%OS")

# Option to display the ms as well. -> Doesn't work properly yet... Should work with the new Timestamp Format
options(digits.secs = 3)

# TODO Delet this part if the Demo-Block is no longer included in the data
# Remove all Demo Trial from the data set
data <- data %>%
  filter(Block != "Demo")

# =============================================
# CALCULATE VALUES PER SEQUENCE
# Calculate Error_Rate for each sequence
temp_get_TargetsHit <- data %>%
  group_by(Condition, Participant, TrialNumber, Block)  %>%
  summarise(ErrorRate = 1 - mean(TargetIsHit))


# Calculate Movement Time for each sequence
# Get first Timestamp (TargetHighlighted)of  a sequence
temp_get_start_time <- data %>%
  select(
    Participant,
    Condition,
    Block,
    TrialNumber,
    TargetNumber,
    StartTime = TargetHighlighted) %>%
  filter(TargetNumber == 1) %>%
  select(-TargetNumber)

# Get last Timestamp (TargetClicked) of a sequence
temp_get_end_time <- data %>%
  select(
    Participant,
    Condition,
    Block,
    TrialNumber,
    TargetNumber,
    EndTime = TargetClicked) %>%
  filter(TargetNumber == 5) %>%
  select(-TargetNumber)

# Create table with both first and last timestamp of a sequence and calculate the difference
data_per_sequence <- data %>%
  select(
    Participant,
    Condition,
    Block,
    TrialNumber
    ) %>%
  full_join(temp_get_start_time) %>%
  full_join(temp_get_end_time) %>%
  mutate(MovementTime = as.numeric(EndTime - StartTime, unit ="secs")) %>%
  unique() %>%
  full_join(temp_get_TargetsHit)

# =============================================
# CALCULATE VALUES FOR WHOLE TRIAL
# Calculate total (sum) movement time per trial 
movement_time_per_trial <- aggregate(MovementTime ~ Condition + Participant + TrialNumber, data = data_per_sequence, sum)

# Calculate average (mean) error rate per trial
error_rate_per_trial <- aggregate(ErrorRate ~ Condition + Participant + TrialNumber, data = data_per_sequence, mean)

# Data for each trial
data_per_trial <- movement_time_per_trial %>%
  full_join(error_rate_per_trial)

# Data for trials in Regular Edge condition
data_regular_edge_per_trial <- data_per_trial %>%
  filter(Condition == "Regular Edge")

# Data for trials in Virtual Edge condition
data_virtual_edge_per_trial <- data_per_trial %>%
  filter(Condition == "Virtual Edge")

```

## Plots for regular edge condition
*Note:* With "trial" we mean the completion of one pointing exercise containing 10 sequences and every sequence is composed of 6 targets on which the participant has to click.

### Movement time per trial for regular edge condition (boxplot)
Boxplot to summarize the times that participant used to complet one task.
```{r boxplot_for_ movement_time}
# Boxplot of the average time participant needed to finish one pointing task
boxplot_movement_time <- boxplot(data_movement_time[4:7], names = c('Trackpad', 'Index Finger', 'Thumb', 'Sway Mode'), xlab = 'Input Mode', ylab = 'Movement Time in ms')
```

### Average movement time per participant for regular edge condition (lineplot)
Lineplot which displays the average time that each participant needed to complete a task.
```{r lineplot_for_movement_time}
# Analysis of average movent time per input mode trial for each participant
average_movement_time_per_participant <- aggregate(data_movement_time[4:7], list(data_movement_time$Participant), mean) %>%
  rename('Participant' = Group.1, 'Trackpad' = MovementTime_trackpad, 'Index Finger' = MovementTime_index_finger, 'Thumb' = MovementTime_thumb, 'Sway Mode' = MovementTime_sway) %>%
  gather(key = Input_Mode, value = Average_Movement_Time, c('Trackpad', 'Index Finger', 'Thumb', 'Sway Mode'))
```

```{r lineplot_for_movement_time_plot, echo=FALSE}
# Lineplot of the calculated movement time average
ggplot (data = average_movement_time_per_participant, mapping = aes(x = fct_relevel(Input_Mode, "Trackpad", "Index Finger", "Thumb", "Sway Mode"), y = Average_Movement_Time, col = Participant, group = Participant)) +
  geom_point() +
  geom_line() +
  labs(x = 'Input Mode', y = 'Movement Time in ms' )
```

### Error rate per task for regular edge condition (boxplot)
Boxplot to summarize the error rates participant had for each completed task.
```{r boxplot_for_error_rate}
# Boxplot of the average error rate that participants have for one pointing task
boxplot_error_rate <- boxplot(data_error_rate[4:7], names = c('Trackpad', 'Index Finger', 'Thumb', 'Sway Mode'), xlab = 'Input Mode', ylab = 'Error Rate in %')
```

### Average error rate per participant for regular edge condition (lineplot)
Lineplot which displays the average error rate each participant had.
```{r lineplot_for_error_rate}
# Analysis of average error rate per input mode trial for each participant
average_error_rate_per_participant <- aggregate(data_error_rate[4:7], list(data_error_rate$Participant), mean) %>%
  rename('Participant' = Group.1, 'Trackpad' = ErrorRate_trackpad, 'Index Finger' = ErrorRate_index_finger, 'Thumb' = ErrorRate_thumb, 'Sway Mode' = ErrorRate_sway) %>%
  gather(key = Input_Mode, value = Average_Error_Rate, c('Trackpad', 'Index Finger', 'Thumb', 'Sway Mode'))
```
```{r lineplot_for_error_rate_plot, echo=FALSE}
# Lineplot of the calculated error rate average
ggplot(data = average_error_rate_per_participant, mapping = aes(x = fct_relevel(Input_Mode, "Trackpad", "Index Finger", "Thumb", "Sway Mode"), y = Average_Error_Rate, col = Participant, group = Participant)) +
  geom_point() +
  geom_line() +
  labs(x = 'Input Mode', y = 'Error Rate in %')
```

## Plots for virtual edge condition
*Note:* With "trial" we mean the completion of one pointing exercise containing 10 sequences and every sequence is composed of 6 targets on which the participant has to click.

### Movement time per trial for virtual edge condition (boxplot)
Boxplot to summarize the times that participant used to complet one task.
```{r boxplot_for_ movement_time}
# Boxplot of the average time participant needed to finish one pointing task
boxplot_movement_time <- boxplot(data_movement_time[4:7], names = c('Trackpad', 'Index Finger', 'Thumb', 'Sway Mode'), xlab = 'Input Mode', ylab = 'Movement Time in ms')
```

### Average movement time per participant for virtual edge condition (lineplot)
Lineplot which displays the average time that each participant needed to complete a task.
```{r lineplot_for_movement_time}
# Analysis of average movent time per input mode trial for each participant
average_movement_time_per_participant <- aggregate(data_movement_time[4:7], list(data_movement_time$Participant), mean) %>%
  rename('Participant' = Group.1, 'Trackpad' = MovementTime_trackpad, 'Index Finger' = MovementTime_index_finger, 'Thumb' = MovementTime_thumb, 'Sway Mode' = MovementTime_sway) %>%
  gather(key = Input_Mode, value = Average_Movement_Time, c('Trackpad', 'Index Finger', 'Thumb', 'Sway Mode'))
```

```{r lineplot_for_movement_time_plot, echo=FALSE}
# Lineplot of the calculated movement time average
ggplot (data = average_movement_time_per_participant, mapping = aes(x = fct_relevel(Input_Mode, "Trackpad", "Index Finger", "Thumb", "Sway Mode"), y = Average_Movement_Time, col = Participant, group = Participant)) +
  geom_point() +
  geom_line() +
  labs(x = 'Input Mode', y = 'Movement Time in ms' )
```

### Error rate per task for virtual edge condition (boxplot)
Boxplot to summarize the error rates participant had for each completed task.
```{r boxplot_for_error_rate}
# Boxplot of the average error rate that participants have for one pointing task
boxplot_error_rate <- boxplot(data_error_rate[4:7], names = c('Trackpad', 'Index Finger', 'Thumb', 'Sway Mode'), xlab = 'Input Mode', ylab = 'Error Rate in %')
```

### Average error rate per participant for virtual edge condition (lineplot)
Lineplot which displays the average error rate each participant had.
```{r lineplot_for_error_rate}
# Analysis of average error rate per input mode trial for each participant
average_error_rate_per_participant <- aggregate(data_error_rate[4:7], list(data_error_rate$Participant), mean) %>%
  rename('Participant' = Group.1, 'Trackpad' = ErrorRate_trackpad, 'Index Finger' = ErrorRate_index_finger, 'Thumb' = ErrorRate_thumb, 'Sway Mode' = ErrorRate_sway) %>%
  gather(key = Input_Mode, value = Average_Error_Rate, c('Trackpad', 'Index Finger', 'Thumb', 'Sway Mode'))
```
```{r lineplot_for_error_rate_plot, echo=FALSE}
# Lineplot of the calculated error rate average
ggplot(data = average_error_rate_per_participant, mapping = aes(x = fct_relevel(Input_Mode, "Trackpad", "Index Finger", "Thumb", "Sway Mode"), y = Average_Error_Rate, col = Participant, group = Participant)) +
  geom_point() +
  geom_line() +
  labs(x = 'Input Mode', y = 'Error Rate in %')
```


## Statistical analysis

### ANOVA

#### Speed
Summary of the ANOVA test for Speed:
```{r anova_speed, echo=FALSE}
fit_speed <- aov(MovementTime ~ Condition, data_raw)
summary(fit_speed)
m.res <- resid(fit_speed)
plot(data_raw$MovementTime, m.res, ylab="Residuals", xlab="MovementTime")
```

#### Accuracy
Summary of the ANOVA test for Accuracy:
```{r anova_accuracy, echo=FALSE}
fit_accuracy <- aov(ErrorRate ~ Condition, data_raw)
summary(fit_accuracy)
m.res <- resid(fit_accuracy)
plot(data_raw$ErrorRate, m.res, ylab="Residuals", xlab="ErrorRate")
```

#### Throughput
Summary of the ANOVA test for Throughput:
```{r anova_throughput, echo=FALSE}
fit_throughput <- aov(Throughput ~ Condition, data_raw)
summary(fit_throughput)
m.res <- resid(fit_throughput)
plot(data_raw$Throughput, m.res, ylab="Residuals", xlab="Throughput")
```

We understand from these ANOVA tests that not all the means are equals. We still have to search which pairs of conditions. For that purpose, we condcut a Post Hoc Test.

### Tukey Test

#### Speed
Summary of the Tukey test for Speed:
```{r tukeyhsd_speed, echo=FALSE}
TukeyHSD(fit_speed)
par(mar=c(5,10,4,2)+0.1) # Add additional margin to the left for fitting the label size

# This hack is used to set a more specific title than the default one generated by R
par(col.main = "white")
plot(TukeyHSD(fit_speed), las=1)
par(col.main = "black")
title(main = "Speed - 95% family-wise confidence level")
```


#### Accuracy
Summary of the Tukey test for Accuracy:
```{r tukeyhsd_accuracy, echo=FALSE}
TukeyHSD(fit_accuracy)
par(mar=c(5,10,4,2)+0.1) # Add additional margin to the left for fitting the label size

# This hack is used to set a more specific title than the default one generated by R
par(col.main = "white")
plot(TukeyHSD(fit_accuracy), las=1)
par(col.main = "black")
title(main = "Accuracy - 95% family-wise confidence level")
```


#### Throughput
Summary of the Tukey test for Throughput:
```{r tukeyhsd_throughput, echo=FALSE}
TukeyHSD(fit_throughput)
par(mar=c(5,10,4,2)+0.1) # Add additional margin to the left for fitting the label size

# This hack is used to set a more specific title than the default one generated by R
par(col.main = "white")
plot(TukeyHSD(fit_throughput), las=1)
par(col.main = "black")
title(main = "Throughput - 95% family-wise confidence level")
```
