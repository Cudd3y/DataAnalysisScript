)
import::from(car, qqPlot, ncvTest, sigmaHat)
import::from(nortest, lillie.test)
import::from(lawstat, levene.test)
import::from(ARTool, art)
import::from(multcomp, glht, mcp)
source("mean_cl_geom.R") # for mean_cl_geom()
```
### Data Import
Load all data that is stored in the corresponding folder
```{r import}
# Create a function that imports all .csv files from a directory "ExperimentalData"
# Put all your data files from the data collection software in the folder "ExperimentalData".
# file_list <- list.files(path = file.path("ExperimentalData"), pattern = "*.csv", recursive = TRUE, full.names = TRUE)
# data_raw <- do.call("rbind", lapply(file_list, function(filename)
# data.frame(read.delim(filename, sep = ";"))))
# because of a coding problem, participants 11 - 17 were coded as 1 - 7. To correct this problem, we import the data for each participant separately.
data1 <- data.frame(read.delim("ExperimentalData/pointing_1.csv", sep = ";"))
data2 <- data.frame(read.delim("ExperimentalData/pointing_2.csv", sep = ";"))
data3 <- data.frame(read.delim("ExperimentalData/pointing_3.csv", sep = ";"))
data4 <- data.frame(read.delim("ExperimentalData/pointing_4.csv", sep = ";"))
data5 <- data.frame(read.delim("ExperimentalData/pointing_5.csv", sep = ";"))
data6 <- data.frame(read.delim("ExperimentalData/pointing_6.csv", sep = ";"))
data7 <- data.frame(read.delim("ExperimentalData/pointing_7.csv", sep = ";"))
data8 <- data.frame(read.delim("ExperimentalData/pointing_8.csv", sep = ";"))
data9 <- data.frame(read.delim("ExperimentalData/pointing_9.csv", sep = ";"))
data10 <- data.frame(read.delim("ExperimentalData/pointing_10.csv", sep = ";"))
data11 <- data.frame(read.delim("ExperimentalData/pointing_11.csv", sep = ";"))
data11$Part <- rep(11,nrow(data11))
data12 <- data.frame(read.delim("ExperimentalData/pointing_12.csv", sep = ";"))
data12$Part <- rep(12,nrow(data12))
data13 <- data.frame(read.delim("ExperimentalData/pointing_13.csv", sep = ";"))
data13$Part <- rep(13,nrow(data13))
data14 <- data.frame(read.delim("ExperimentalData/pointing_14.csv", sep = ";"))
data14$Part <- rep(14,nrow(data14))
data15 <- data.frame(read.delim("ExperimentalData/pointing_15.csv", sep = ";"))
data15$Part <- rep(15,nrow(data15))
data16 <- data.frame(read.delim("ExperimentalData/pointing_16.csv", sep = ";"))
data16$Part <- rep(16,nrow(data16))
data17 <- data.frame(read.delim("ExperimentalData/pointing_17.csv", sep = ";"))
data17$Part <- rep(17,nrow(data17))
data_raw <- rbind(data1, data2, data3, data4, data5, data6, data7, data8, data9, data10, data11, data12, data13, data14, data15, data16, data17)
rm(data1, data2, data3, data4, data5, data6, data7, data8, data9, data10, data11, data12, data13, data14, data15, data16, data17)
```
### Data Clean Up
Before we start with the analysis, we will reduce the dataset to the necessary attributes and calcutate the aggregated values.
```{r clean up}
# Keep only the columns of interest and give them more readable names
data <- data_raw %>%
select(
Participant = Part,
Condition = Cond,
TrialNumber = Rep,
Block,
TargetNumber = Click,
TargetIsHit = Succ,
TargetHighlighted = Tar_t,
TargetClicked = Click_t,
PosX,
PosY,
Distance = Dist
)
# Remove all Demo Trial from the data set
data <- data %>%
filter(TrialNumber != "demo")
data$Participant <- as.factor(data$Participant)
data$Block <- as.factor(data$Block)
# Renaming of cell values in a more meaningful way
data$Condition[data$Condition == '0'] <- "Regular Edge"
data$Condition[data$Condition == '1'] <- "Virtual Edge"
data$Condition <- as.factor(data$Condition)
options(digits.secs = 3) # Set accuracy to one millisecond
# Convert the timestamps into a time format
data$TargetHighlighted <- as.POSIXct(data$TargetHighlighted, format = "%H:%M:%OS")
data$TargetClicked <- as.POSIXct(data$TargetClicked, format = "%H:%M:%OS")
```
### Compute movment time and convert errors to a boolean
```{r}
data <- data %>%
mutate(MovementTime = as.numeric(TargetClicked - TargetHighlighted, unit ="secs"))
data$TargetIsHit[data$TargetIsHit == '0'] <- FALSE
data$TargetIsHit[data$TargetIsHit == '1'] <- TRUE
```
### Calculate values per trial
```{r}
data_per_trial <- data %>%
group_by(Participant, Condition, TrialNumber)  %>%
summarise(ErrorRate = 1 - mean(TargetIsHit, na.rm = T), MovementTime = sum(MovementTime, na.rm = T))
# Data for trials in Regular Edge condition
data_per_trial_regular_edge <- data_per_trial %>%
filter(Condition == "Regular Edge")
# Data for trials in Virtual Edge condition
data_per_trial_virtual_edge <- data_per_trial %>%
filter(Condition == "Virtual Edge")
```
## Exploratory plot
*Note:* With "trial" we mean the completion of one pointing exercise containing 10 sequences (blocks) and every sequence is composed of 5 targets on which the participant has to click.
### Average movement time per participant for regular edge condition (lineplot)
Lineplot which displays the average time that each participant needed to complete a trial.
```{r lineplot_for_movement_time}
ggplot (data = data_per_trial_regular_edge, mapping = aes(x = TrialNumber, y = MovementTime, col = Participant, group = Participant)) +
geom_point() +
geom_line() +
labs(x = 'Trial Number - Regular Edge', y = 'Movement Time per Trial in sec')
```
```{r lineplot_for_error_rate_plot_average}
# Lineplot of the calculated error rate average
ggplot (data = data_per_trial_regular_edge, mapping = aes(x = TrialNumber, y = ErrorRate, col = Participant, group = Participant)) +
geom_point() +
geom_line() +
labs(x = 'Trial Number - Regular Edge', y = 'Error Rate in %')
```
*Note:* With "trial" we mean the completion of one pointing exercise containing 10 sequences and every sequence is composed of 6 targets on which the participant has to click.
### Average movement time per participant for virtual edge condition (lineplot)
Lineplot which displays the average time that each participant needed to complete a task.
```{r lineplot_for_movement_time_task}
ggplot (data = data_per_trial_virtual_edge, mapping = aes(x = TrialNumber, y = MovementTime, col = Participant, group = Participant)) +
geom_point() +
geom_line() +
labs(x = 'Trial Number - Virtual Edge', y = 'Movement Time per Trial in sec')
```
### Average error rate per participant for virtual edge condition (lineplot)
```{r lineplot_for_error_rate_plot}
# Lineplot of the calculated error rate average
ggplot (data = data_per_trial_virtual_edge, mapping = aes(x = TrialNumber, y = ErrorRate, col = Participant, group = Participant)) +
geom_point() +
geom_line() +
labs(x = 'Trial Number - Virtual Edge', y = 'Error Rate in %')
```
### Relationship between MovementTime and Regular Edge Trials.
```{r}
data_per_trial_regular_edge %>%
ggplot(., aes(x = TrialNumber, y = MovementTime)) +
geom_point() +
geom_smooth(method = "lm", size = 1.5, color = "red")
```
### Relationship between MovementTime and Virtual Edge Trials.
```{r}
data_per_trial_virtual_edge %>%
ggplot(., aes(x = TrialNumber, y = MovementTime)) +
geom_point() +
geom_smooth(method = "lm", size = 1.5, color = "red")
```
### Movemement time: mean and unadjusted confidence interval for each trial and each condition.
```{r}
ggplot(data_per_trial, aes(TrialNumber, MovementTime, color=Condition)) +
stat_summary(fun.data = "mean_cl_normal", position = position_dodge(width = 1)) + scale_color_brewer(palette = "Set1")
```
```{r}
ggplot(data_per_trial, aes(TrialNumber, MovementTime, fill=Condition)) +
stat_summary(fun.data = "mean_cl_normal", geom = "bar", position = "dodge") +  scale_color_brewer(palette = "Set1")
```
Movement time: we see that the mean for virtual edges is slightly smaller and the confidence intervals overlap. We also see the difference between the two conditions seem to increase with the number of trials.
### Relationship between Error Rate and Regular Edge Trials.
```{r}
data_per_trial_regular_edge %>%
ggplot(., aes(x = TrialNumber, y = ErrorRate)) +
geom_point() +
geom_smooth(method = "lm", size = 1.5, color = "red")
```
### Relationship between Error Rate and Virtual Edge Trials.
```{r}
data_per_trial_virtual_edge %>%
ggplot(., aes(x = TrialNumber, y = ErrorRate)) +
geom_point() +
geom_smooth(method = "lm", size = 1.5, color = "red")
```
### Error Rate: mean and unadjusted confidence interval for each trial and each condition.
```{r}
ggplot(data_per_trial, aes(TrialNumber, ErrorRate, color=Condition)) +
stat_summary(fun.data = "mean_cl_normal", position = position_dodge(width = 1)) + scale_color_brewer(palette = "Set1")
```
```{r}
ggplot(data_per_trial, aes(TrialNumber, ErrorRate, fill=Condition)) +
stat_summary(fun.data = "mean_cl_normal", geom = "bar", position = "dodge") +  scale_color_brewer(palette = "Set1")
```
Error Rate: We see that the mean for virtual edges is smaller and the confidence intervals do not lap.
## Assumbption on the data (original data)
### Normality assumption for Movement Time
```{r}
par(mfrow = c(1,2)) #plot two plots next to each other
data_per_trial %>%
group_by(Condition) %>%
do({
qqPlot(.$MovementTime)
title(main=.$Condition[[1]])
tidy(lillie.test(.$MovementTime))
})
par(mfrow = c(1,1)) # sets back the default
```
## Homogeneity Assumption for Movement Time
```{r message=FALSE, warning=FALSE, include=FALSE}
levene.test(data_per_trial$MovementTime, data_per_trial$Condition, location = "median")
```
### Normality assumption for Error Rate
```{r}
par(mfrow = c(1,2)) #plot two plots next to each other
data_per_trial %>%
group_by(Condition) %>%
do({
qqPlot(.$ErrorRate)
title(main=.$Condition[[1]])
tidy(lillie.test(.$ErrorRate))
})
par(mfrow = c(1,1)) # sets back the default
```
## Homogeneity Assumption for Error Rate
```{r message=FALSE, warning=FALSE, include=FALSE}
levene.test(data_per_trial$ErrorRate, data_per_trial$Condition, location = "median")
```
## Log Transformation for Error Rate
### Normality assumption for log of Error Rate
```{r}
par(mfrow = c(1,2)) #plot two plots next to each other
data_per_trial %>%
group_by(Condition) %>%
do({
qqPlot(log(.$ErrorRate + 2))
title(main=.$Condition[[1]])
tidy(lillie.test(log(.$ErrorRate + 2)))
})
par(mfrow = c(1,1)) # sets back the default
```
## Homogeneity Assumption for Error Rate
```{r message=FALSE, warning=FALSE, include=FALSE}
levene.test(log(data_per_trial$ErrorRate + 2), data_per_trial$Condition, location = "median")
```
## Linear model for MovementTime
We fit a linear model between MovementTime, Condition and their interaction.
```{r}
fit_movementTime <- lm(MovementTime ~ Condition*TrialNumber, data_per_trial)
```
### Analysis of variance (ANOVA)
Comparing to the null model: (there's no relationship between movementTime and condition)
```{r}
anova_movementTime <- tidy(anova(fit_movementTime))
anova_movementTime
```
### Update model to exclude interaction
```{r}
fit_movementTime <- update(fit_movementTime, .~. - Condition:TrialNumber)
```
### AIC model assessment
Goal: find the model with lowest AIC
```{r}
step_backward_result <-
MASS::stepAIC(fit_movementTime,
direction = "backward",
trace = TRUE
)
```
**Interpretation:** The AIC-score shows the best (lowest) value when the trial number is removed.
### Update model to exclude trial number
```{r}
fit_movementTime <- update(fit_movementTime, .~. - TrialNumber)
```
Then, we plot the residuals to check if they seem to be normally distributed
```{r}
p_M_C_resid <- data_per_trial %>%
ggplot(., aes(x = MovementTime, y = fit_movementTime$residuals)) +
geom_point() +
geom_hline(yintercept = 0, col = "red")
p_M_C_resid
```
```{r}
car::qqPlot(fit_movementTime$residuals)
```
From QQ-plot, we see that the residuals are normally distributed.
We check if the residuals have similar variance
```{r}
car::ncvTest(fit_movementTime)
```
### Log-transformation of movement time
```{r}
fit_movementTime <- lm(log(MovementTime) ~ Condition, data_per_trial)
```
Then, we plot the residuals to check if they seem to be normally distributed
```{r}
p_M_C_resid <- data_per_trial %>%
ggplot(., aes(x = MovementTime, y = fit_movementTime$residuals)) +
geom_point() +
geom_hline(yintercept = 0, col = "red")
p_M_C_resid
```
Then, we plot the residuals to check if they seem to be normally distributed
```{r}
p_M_C_resid <- data_per_trial %>%
ggplot(., aes(x = MovementTime, y = fit_movementTime$residuals)) +
geom_point() +
geom_hline(yintercept = 0, col = "red")
p_M_C_resid
```
```{r}
car::qqPlot(fit_movementTime$residuals)
```
From QQ-plot, we see that the residuals are normally distributed.
We check if the residuals have similar variance
```{r}
car::ncvTest(fit_movementTime)
```
### Reverse the log transformation
```{r}
ci_pairwise_antilog_ratio <-
tidy(confint(pairwise_movementTime)) %>%
mutate(
estimate = exp(estimate),
conf.low = exp(conf.low),
conf.high = exp(conf.high)
) %>%
separate(lhs, c("competitor", "Condition"), sep = " - ") %>%
select(-rhs)
ci_pairwise_antilog_ratio
```
```{r}
p_pairwise_antilog_ratio <-
ci_pairwise_antilog_ratio %>%
mutate(hypothesis = str_c(competitor, " - ", Condition)) %>%
ggplot(aes(x = hypothesis, y = estimate, ymin = conf.low, ymax = conf.high)) +
geom_hline(yintercept = 1, color = "red") +
geom_pointrange() +
coord_flip() +
xlab("hypothesis (log)") +
ylab("Ratio movement time")  +
theme_grey(base_size = 22)
p_pairwise_antilog_ratio
```
```{r}
summary_geom_mean <-
data_per_trial %>%
group_by(Condition) %>%
do({mean_cl_geom(.$MovementTime)}) %>%
rename(
mean_geom = y,
conf_low = ymin,
conf_high = ymax) %>%
ungroup()
ci_pairwise_antilog_s <-
summary_geom_mean %>%
select(Condition, mean_geom) %>%
mutate(Condition = as.character(Condition)) %>%
right_join(ci_pairwise_antilog_ratio, by = c("Condition")) %>%
mutate(
estimate_s = (mean_geom * estimate) - mean_geom,
conf_low_s = (mean_geom * conf.low) - mean_geom,
conf_high_s = (mean_geom * conf.high) - mean_geom
) %>%
select(Condition, competitor, estimate_s, conf_low_s, conf_high_s)
ci_pairwise_antilog_s
```
```{r}
p_pairwise_antilog_s <-
ci_pairwise_antilog_s %>%
mutate(hypothesis = str_c(competitor, " - ", Condition)) %>%
ggplot(aes(x = hypothesis, y = estimate_s, ymin = conf_low_s, ymax = conf_high_s)) +
geom_pointrange() +
geom_hline(yintercept = 0, color = "red") +
ylab("milliseconds") +
xlab("") +
coord_flip() +
theme_grey(base_size = 22)
p_pairwise_antilog_s
```
## Linear model for Error Rate
We fit a linear model between Error Rate, Condition and their interaction.
```{r}
fit_errorRate <- lm(log(ErrorRate +2) ~ Condition*TrialNumber, data_per_trial)
```
### Analysis of variance (ANOVA)
Comparing to the null model: (there's no relationship between movementTime and condition)
```{r}
anova_errorRate <- tidy(anova(fit_errorRate))
anova_errorRate
```
### Update model to exclude interaction
```{r}
fit_errorRate <- update(fit_errorRate, .~. - Condition:TrialNumber)
```
### AIC model assessment
Goal: find the model with lowest AIC
```{r}
step_backward_result <-
MASS::stepAIC(fit_errorRate,
direction = "backward",
trace = TRUE
)
```
**Interpretation:** The AIC-score shows the best (lowest) value when the trial number is removed.
### Update model to exclude trial number
```{r}
fit_errorRate <- update(fit_errorRate, .~. - TrialNumber)
```
Then, we plot the residuals to check if they seem to be normally distributed
```{r}
p_E_C_resid <- data_per_trial %>%
ggplot(., aes(x = log(ErrorRate + 2), y = fit_errorRate$residuals)) +
geom_point() +
geom_hline(yintercept = 0, col = "red")
p_E_C_resid
```
```{r}
p_E_C_resid <- data_per_trial %>%
ggplot(., aes(x = Condition, y = fit_errorRate$residuals)) +
geom_point() +
geom_hline(yintercept = 0, col = "red")
p_E_C_resid
```
```{r}
car::qqPlot(fit_errorRate$residuals)
```
From QQ-plot, we see that the residuals do not follow a normal distribution.
We check if the residuals have similar variance
```{r}
car::ncvTest(fit_errorRate)
```
Since the residuals are neither normally distributed nor have similar variance, we perform a Aligned Rank Transformation (ART)
```{r}
art_errorRate <- art(ErrorRate ~ Condition, data_per_trial)
data_per_trial$ErrorRate_art_Condition <- art_errorRate$aligned.ranks$Condition
m_art_Condition <- lm(ErrorRate_art_Condition ~ Condition, data_per_trial)
summary(m_art_Condition)
```
### Pairwise comparison for movement time
```{r}
pairwise_movementTime <- glht(fit_movementTime, linfct = mcp(Condition = "Tukey"))
ci_pairwise_movementTime <- tidy(confint(pairwise_movementTime))
scale_factor <- sigmaHat(fit_movementTime)
ci_pairwise_movementTime <-
ci_pairwise_movementTime %>%
mutate(
estimate  = estimate / scale_factor,
conf.low  = conf.low / scale_factor,
conf.high = conf.high / scale_factor
)
ci_pairwise_movementTime
```
```{r}
p_pairwise_movementTime <-
ci_pairwise_movementTime %>%
ggplot(aes(x = lhs, y = estimate, ymin = conf.low, ymax = conf.high)) +
geom_pointrange() +
geom_hline(yintercept = 0, color = "red") +
xlab("") +
ylab("Cohen's d effect size") +
coord_flip()  +
theme_grey(base_size = 22)
p_pairwise_movementTime
```
### Pairwise comparison for error rate
```{r}
pairwise_art_Condition <- glht(m_art_Condition, linfct = mcp(Condition = "Tukey"))
ci_pairwise_art_Condition <- tidy(confint(pairwise_art_Condition))
scale_factor <- sigmaHat(m_art_Condition)
ci_pairwise_art_Condition <-
ci_pairwise_art_Condition %>%
mutate(
estimate  = estimate / scale_factor,
conf.low  = conf.low / scale_factor,
conf.high = conf.high / scale_factor
)
ci_pairwise_art_Condition
```
```{r}
p_pairwise_art_Condition <-
ci_pairwise_art_Condition %>%
ggplot(aes(x = lhs, y = estimate, ymin = conf.low, ymax = conf.high)) +
geom_pointrange() +
geom_hline(yintercept = 0, color = "red") +
xlab("") +
ylab("Cohen's d effect size") +
coord_flip()  +
theme_grey(base_size = 22)
p_pairwise_art_Condition
```
p_M_C_resid <- data_per_trial %>%
ggplot(., aes(x = MovementTime, y = fit_movementTime$residuals)) +
geom_point() +
geom_hline(yintercept = 0, col = "red")
p_M_C_resid
p_M_C_resid <- data_per_trial %>%
ggplot(., aes(x = MovementTime, y = fit_movementTime$residuals)) +
geom_point() +
geom_hline(yintercept = 0, col = "red")
p_M_C_resid
p_M_C_resid <- data_per_trial %>%
ggplot(., aes(x = MovementTime, y = fit_movementTime$residuals)) +
geom_point() +
geom_hline(yintercept = 0, col = "red")
p_M_C_resid
car::qqPlot(fit_movementTime$residuals)
pairwise_movementTime <- glht(fit_movementTime, linfct = mcp(Condition = "Tukey"))
ci_pairwise_movementTime <- tidy(confint(pairwise_movementTime))
ci_pairwise_movementTime
ci_pairwise_antilog_ratio <-
tidy(confint(pairwise_movementTime)) %>%
mutate(
estimate = exp(estimate),
conf.low = exp(conf.low),
conf.high = exp(conf.high)
) %>%
separate(lhs, c("competitor", "Condition"), sep = " - ") %>%
select(-rhs)
ci_pairwise_antilog_ratio
ci_pairwise_antilog_ratio <-
tidy(confint(pairwise_movementTime)) %>%
mutate(
estimate = exp(estimate),
conf.low = exp(conf.low),
conf.high = exp(conf.high)
) %>%
separate(lhs, c("competitor", "Condition"), sep = " - ") %>%
select(-rhs)
ci_pairwise_antilog_ratio
